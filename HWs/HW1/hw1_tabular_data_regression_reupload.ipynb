{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google sheet with personal questions\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/1kH6AfE3Iu6kdgQsDQvEGXaAkKlhAT6VaxeFOlJpnC0E/edit?usp=sharing\n",
    "\n",
    "Every column corresponds to a single question, every row to a single student.\n",
    "\n",
    "For example, R. Daneel Olivaw need to report questions 1.1, 1.2, 2.2, 2.3, etc.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submiting the answers\n",
    "\n",
    "\n",
    "Google form to submit your answers: https://docs.google.com/forms/d/e/1FAIpQLSd2gNxCq9j8ZE_NzZlV8Q-gTNbiic5Rkx3vitz7vMlfzkzAzQ/viewform?usp=sf_link\n",
    "\n",
    "Google form has fields for all questions, but you only need to answer **your** questions (from google sheet above).\n",
    "\n",
    "Use your **skoltech email**. For Name, Surname use **exactly the same spelling** as in canvas system.\n",
    "\n",
    "---\n",
    "\n",
    "Every question has an information about the type of the answer, e.g.\n",
    "\n",
    "> Observe top 10 observations (int)\n",
    "\n",
    "here your answer must be a single **integer** number.\n",
    "\n",
    "---\n",
    "\n",
    "If your answer is a ``float number``, then it must be provided with **3 decimals after the floating point**, e.g. 1.234\n",
    "\n",
    "---\n",
    "\n",
    "If your answer is a ``list of float or integer numbers or str``, then they should be reported in descending (alphabetical) order, without spacing, divided by a comma, e.g.:\n",
    "\n",
    "10.453,9.112,5.001,5.000 - Right\n",
    "\n",
    "10.453, 9.112, 5.001, 5.000 - WRONG\n",
    "\n",
    "---\n",
    "\n",
    "Part of the tasks, e.g. Q19.1-5, Q20.1-5 do not have corresponding fields in the google form. They are **not optional** and they will be graded manually from your .ipynb file.\n",
    "\n",
    "---\n",
    "\n",
    "If you have any questions regarding this Home Assignment, ask them piazza topic: https://piazza.com/class/kespugtqfrn12g?cid=12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1. House Pricing.\n",
    "by Anvar Kurmukov\n",
    "\n",
    "---\n",
    "\n",
    "By the end of this task you will be able to manipulate huge tabular data:\n",
    "1. Compute different column's statistics (min, max, mean, quantiles etc.);\n",
    "2. Select observations/features by condition/index;\n",
    "3. Create new non-linear combinations of the columns (feature engineering);\n",
    "4. Perform automated data cleaning;\n",
    "\n",
    "and more.\n",
    "\n",
    "---\n",
    "\n",
    "For those who are not familiar with `pandas` we recommend these (alternative) tutorials:\n",
    "\n",
    "1. Single notebook, covers basic pandas functionality (starting with renaming columns ending with using map, apply etc) ~ 30 short examples with links on videos https://nbviewer.jupyter.org/github/justmarkham/pandas-videos/blob/master/pandas.ipynb . Highly recommended for everyone. (about 1-3 hours to go through)\n",
    "\n",
    "2. https://github.com/guipsamora/pandas_exercises/ 11 topics covering all essential functionality with excersises (with solutions).\n",
    "\n",
    "This task will be an easy ride after these tutorials.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using house sale price data from King County, Wahington, USA. This dataset is in public domain and can be obtained from Kaggle: https://www.kaggle.com/harlfoxem/housesalesprediction\n",
    "\n",
    "You need to place `kc_nouse_data.csv` file in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading data\n",
    "\n",
    "As always in Data Science you are starting with making nice cup of tea (or coffee). Your next move is to load the data:\n",
    "\n",
    "- Start with loading `house_data.csv` file using `pd.read_csv()` function.\n",
    "- You may also want to increase maximal displayed pandas columns: set `pd.options.display.max_columns` to 30\n",
    "- Print top 10 observations in the table. `.head()`\n",
    "- Print last 10 observations in the table. `.tail()`\n",
    "- Print all the data columns names using method `.columns`\n",
    "- Print data size (number of rows and columns). This is the `.shape` of the data.\n",
    "\n",
    "*Almost* every python has a `head` and a `tail` just as DataFrames do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe top 10 observations (int)\n",
    "\n",
    "# Q1.1 What is the price of a house with `id` == 7237550310?\n",
    "# Q1.2 How many bedrooms has a house with `id` == 7237550310?\n",
    "# Q1.3 When was the house with `id` == 2414600126 built (`yr_built`)?\n",
    "# Q1.4 What is the `grade` of a house with `id` == 5631500400?\n",
    "# Q1.5 When was the house with `id` == 6414100192 renovated (`yr_renovated`)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe last 10 observations (int)\n",
    "\n",
    "# Q2.1 What is the price of a house with `id` == 263000018?\n",
    "# Q2.2 How many bedrooms has a house with `id` == 291310100?\n",
    "# Q2.3 When was the house with `id` == 1523300141 built (`yr_built`)?\n",
    "# Q2.4 How many floors house with `id` == 2997800021 has?\n",
    "# Q2.5 What is the zipcode of the house with `id` == 7852140040?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase maximal displayed columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe top 10 observations again\n",
    "# Is there any new columns displayed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all the columns/features names (int)\n",
    "\n",
    "# Q3.1 How many columns have `yr_` prefix?\n",
    "# Q3.2 How many columns have `sqft_` prefix?\n",
    "# Q3.3 How many columns assosiated with house earth coordinates are in the data?\n",
    "# Q3.4 How many columns have `rooms` in their names?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print data size (int)\n",
    "\n",
    "# Q4.1 How many observations are in the data?\n",
    "# Q4.2 How many features are in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basic data exploration\n",
    "\n",
    "Lets do some basics:\n",
    "- `.count()` number of not NaN's in every column.\n",
    "- Is there any missing values in the data?\n",
    "- Count number of unique values in every column `.nunique()`. \n",
    "- What does this tells you about the features, which are most likely categorical and which are most likely numerical?\n",
    "- Use pandas `.describe()` to display basic statistic about the data.\n",
    "- Use pandas `.value_counts()` to count number of unique values in a specific column.\n",
    "- Use pandas `.min()`, `.max()`, `.mean()`, `.std()` to display specific statistics about the data.\n",
    "- Use pandas `.dtypes` field to display data types in columns.\n",
    "\n",
    "**Hint**\n",
    "You could use `.sort_index()` or `.sort_values()` to sort the result of `.value_counts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display number of not NaN's in every column (int)\n",
    "\n",
    "# Q5.1 How many NA values are in the `floors` column?\n",
    "# Q5.2 How many NA values are in the `grade` column?\n",
    "# Q5.3 How many NA values are in the `bedrooms` column?\n",
    "# Q5.4 How many NA values are in the `yr_built` column?\n",
    "# Q5.5 How many NA values (not zeros, but empty, missing values) are in the `yr_renovated` column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique values in every column (int)\n",
    "\n",
    "# Q6.1 How many unique values are in the `bedrooms` column?\n",
    "# Q6.2 How many unique values are in the `grade` column?\n",
    "# Q6.3 How many unique values are in the `yr_renovated` column?\n",
    "# Q6.4 How many unique values are in the `bathrooms` column?\n",
    "# Q6.5 How many unique values are in the `long` column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count frequency of the values in different columns (list of ints in ascending order)\n",
    "# You could select a column using same syntax as for selecting a key from a dictionary: `data[colname]`\n",
    "\n",
    "# Q7.1 For every unique `floors` value give its number of occurences.\n",
    "# Q7.2 For every unique `condition` value give its number of occurences.\n",
    "# Q7.3 For every unique `bedrooms` value give its number of occurences.\n",
    "# Q7.4 For every unique `grade` value give its number of occurences.\n",
    "# Q7.5 For every unique `view` value give its number of occurences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic data statistics using .describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some column statistics (list of floats, rounded up to 3 digits, e.g. 1.234)\n",
    "\n",
    "# Q8.1 What are the max, min, mean and the std of the `floors` column?\n",
    "# Q8.2 What are the max, min, mean and the std of the `bedrooms` column?\n",
    "# Q8.3 What are the max, min, mean and the std of the `sqft_living` column?\n",
    "# Q8.4 What are the max, min, mean and the std of the `price` column?\n",
    "# Q8.5 What are the max, min, mean and the std of the `long` column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data types of all columns (int)\n",
    "\n",
    "# Q9.1 How many columns have `object` data type?\n",
    "# Q9.2 How many columns have `int64` data type?\n",
    "# Q9.3 How many columns have `float64` data type?\n",
    "\n",
    "# Display data types of all columns (list of str)\n",
    "# Q9.4 What are the columns with dtype == `float64`?\n",
    "# Q9.5 What are the columns with dtype == `int64`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data selection\n",
    "\n",
    "In pandas.DataFrame you could select\n",
    "\n",
    "1. Row/s by position (integer number \\[0 .. number of rows - 1\\]) `.iloc` or by DataFrame.index `.loc`:\n",
    "```\n",
    "data.loc[0]\n",
    "data.loc[5:10]\n",
    "data.iloc[0]\n",
    "data.iloc[5:10]\n",
    "```\n",
    "*Though, this is probably the worst way to manipulate rows.*\n",
    "\n",
    "2. Columns by name\n",
    "```\n",
    "data[columname]\n",
    "```\n",
    "3. Row/s and columns\n",
    "```\n",
    "data.loc[10, columname]\n",
    "data.iloc[10, columname]\n",
    "```\n",
    "4. Using boolean mask\n",
    "```\n",
    "mask = data[columname] > value\n",
    "data[mask]\n",
    "```\n",
    "You could combine multiple conditions using `&` or `|` (and, or)\n",
    "\n",
    "```\n",
    "cond1 = data[columname1] > value1\n",
    "cond2 = data[columname2] > value2\n",
    "data[cond1 & cond2]\n",
    "```\n",
    "5. Using queries `.query()`:\n",
    "```\n",
    "value = 5\n",
    "data.query(\"columname > value\")\n",
    "```\n",
    "You could combine multiple conditions using `and`, `or`\n",
    "\n",
    "```\n",
    "data.query(\"(columname1 > value1) and (columname2 > value2)\")\n",
    "```\n",
    "and others. See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html for more examples.\n",
    "\n",
    "*Remember to use different quotation marks \" or ' for columnname inside a query.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting DataFrame index to be an `id` column, now .loc and .iloc will have different behavior\n",
    "data.index = data.id\n",
    "\n",
    "# dropping `id` column, since now it is an index\n",
    "data.drop('id', axis=1, inplace=True)\n",
    "\n",
    "# sort data by index for clarity\n",
    "data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows by position (int) \n",
    "\n",
    "# Q10.1 How many bedrooms have a house on row 777?\n",
    "# Q10.2 When was built a house on row 9999?\n",
    "# Q10.3 How many floors have a house on row 1337?\n",
    "# Q10.4 How many bathrooms have a house on row 314?\n",
    "# Q10.5 What is the grade of a house on row 2718?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows by index (int)\n",
    "\n",
    "# Q11.1 How many times the house with index 1000102 were sold?\n",
    "# Q11.2 What is the price of the house with index 9842300095?\n",
    "# Q11.3 When was built the house with index 104510440?\n",
    "# Q11.4 What is the condition of a house with index 252000300?\n",
    "# Q11.5 What is the living area (in square feets) of the house with index 1225069038?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mask or .query syntax select rows/columns (int)\n",
    "\n",
    "# Q12.1 How many houses were built during American Great Depression (1929–1939)? Including both start and end year.\n",
    "# Q12.2 When was built the only house with basement area = 1024 sqft?\n",
    "# Q12.3 How many houses are with the highest possible grade?\n",
    "# Q12.4 When was built a house with maximal number of bedrooms?\n",
    "# Q12.5 How many houses were sold for 256000 dollars?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mask or .query syntax select rows/columns (int)\n",
    "\n",
    "# Q13.1 How many houses with the waterfront (=1) were built duroing Nixon's presidency (1969—1974)? Including both start and end year.\n",
    "# Q13.2 How many houses, built before first human in space (<1961), have high condition (=5)?\n",
    "# Q13.3 How many houses are with 6 bedrooms and less than 2000 sqft living area?\n",
    "# Q13.4 What was the price of a house with 5 bathrooms, built in 1998 and graded with 10 score?\n",
    "# Q13.5 How many floors has a house built in 1999 with 5 bedrooms and 3400 sqft living area?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mask or .query syntax select rows/columns and compute simple statistics (float)\n",
    "\n",
    "# Q14.1 What was the average (sold) price of a houses built in the year of Cuban Missile Crisis (1962)?\n",
    "# Q14.2 What was the price of the most expensive house sold, built between 1991 and 2000?\n",
    "# Q14.3 What was the price of the least expensive house sold, built between 1991 and 2000?\n",
    "# Q14.4 What is the median number of bathrooms in houses with grade above 9 (10 and more)?\n",
    "# Q14.5 What is the median grade of houses with most popular zipcode value?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Creating new columns\n",
    "\n",
    "\n",
    "Creating new column of pandas.DataFrame is as easy as:\n",
    "```\n",
    "data['new_awesome_column'] = [] \n",
    "```\n",
    "that's it. But such a column is relatively useless. \n",
    "Typically, you would compute something new based on existing data and save it in a new column. \n",
    "For example one might want to compute total area of the house as a sum of all `sqft_` columns, or\n",
    "create a boolean column of whether the house has `grade` > 2 or anything else:\n",
    "\n",
    "```\n",
    "data['total_area'] = data[col1] + data[col2] + ...\n",
    "data['high_value'] = data[col] > 5\n",
    "```\n",
    "\n",
    "Pandas also provides another powerfull tool: `.apply`, `.map()`, `.applymap()` methods (they are kinda the same, but not quite). https://stackoverflow.com/questions/19798153/difference-between-map-applymap-and-apply-methods-in-pandas .\n",
    "They allow you to *apply* some function to every value in the column/s (row-wise) or row (column-wise) or cell (element-wise). For example, same computations of `total_area` and `high_value` using `.apply()`:\n",
    "```\n",
    "data['total_area'] = data[[col1, col2, col3]].apply(sum, axis=1)\n",
    "\n",
    "```\n",
    "you are not restricted to existent functions, `.apply()` accepts any function (including lambda functions):\n",
    "\n",
    "```\n",
    "data['total_area'] = data[[col1, col2, col3]].apply(lambda x: x[0]+x[1]+x[2], axis=1)\n",
    "```\n",
    "or ordinary python function (if this it should have complex behaviour):\n",
    "```\n",
    "def _sum(x):\n",
    "    total = 0\n",
    "    for elem in x:\n",
    "        total += elem\n",
    "    return total\n",
    "    \n",
    "data['total_area'] = data[[col1, col2, col3]].apply(_sum, axis=1) \n",
    "```\n",
    "Many pandas methods has `axis` parameter `axis=0` refers to rows, `axis=1` refers to columns.\n",
    "\n",
    "*Warning. You should never use for loops to sum numerical elements from the container.*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create `was_renovated` column. Bool column (0, 1) indicating whether the house was renovated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns using the old ones (new column in your DataFrame)\n",
    "\n",
    "# Q15.1 Create a `sqft_tot_area` column (sum of all columns with `sqft_` prefix) using any method above\n",
    "# Q15.2 Create a new column `sqm_tot_area` using `sqft_tot_area` and the fact that 1 foot = 0.3048 meters\n",
    "# Q15.3 Create a new column `sqm_aver_floor_area` by dividing total area (in meters) by number of floors\n",
    "# Q15.4 Create a new column `price_cat` by splitting a `price` into 5 ([1..5]) distinct intervals: 0 < x <=20%,\n",
    "# 20% < x <= 40%, ... 80% < x <= 100% percentiles. You could use `.quantile()` to compute percentiles.\n",
    "# Q15.5 Create a new bool column `high_class` it is True if the house has grade >= 9 and condition >= 4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mask or .query syntax select rows/columns (float)\n",
    "\n",
    "# Q16.1 What is the average price of the house of the high_class(=True)?\n",
    "# Q16.2 What is the average total_area (in meters) of the house from highest price category?\n",
    "# Q16.3 What is the maximal number of floors amongst houses with the lowest price category?\n",
    "# Q16.4 What is the most frequent zipcode amongst houses with the lowest price category?\n",
    "# Q16.5 What is the minimal number of bathrooms in houses with high_class=True?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Basic date processing\n",
    "\n",
    "You figure out that column `date` is to harsh for you, so you decided to convert it to a more plausible format:\n",
    "\n",
    "- Use pandas method `to_datetime()` to convert the date to a good format.\n",
    "- Exctract `year`, `month`, `day` and `weekday` from your new date column. Save them to separete columns.\n",
    "- How many columns has your data now?\n",
    "- Drop column `date`, remember to set `inplace` parameter to True.\n",
    "\n",
    "\n",
    "**Hint** for datetime formatted date you could extract the `year` as follow:\n",
    "```\n",
    "data.date.dt.year\n",
    "```\n",
    "\n",
    "Very often date could be a ridiculously rich feature, sometimes it is holidays that matters, sometimes weekends, sometimes some special days like **black friday**. \n",
    "\n",
    "Learn how to work with date in Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns based on `date` column\n",
    "\n",
    "# Q17.1 Convert date to datetime format\n",
    "# Q17.2 Extract and store `year`\n",
    "# Q17.3 Extract and store `month`\n",
    "# Q17.4 Extract and store `day`\n",
    "# Q17.5 Extract and store `weekday`\n",
    "# Q17.6 Create a new column `house_age_10` - the age of the house in full decades (e.g. 9 year old house - 0, 21 year old house - 2),\n",
    "# using `yr_built` and 'year' columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column `date`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find some date related information from the data (int, Sunday has index 0)\n",
    "\n",
    "# Q18.1 What is the most popular selling weekday?\n",
    "# Q18.2 What is the most popular selling month?\n",
    "# Q18.3 What is the least popular selling weekday?\n",
    "# Q18.4 What is the median age of the house (on a first available sold date)? (float)\n",
    "# Q18.5 How many houses were sold on America's Independence Day (July, 4)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Groupby\n",
    "from the documentation https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html\n",
    "\n",
    "By “group by” we are referring to a process involving one or more of the following steps:\n",
    "\n",
    "    - Splitting the data into groups based on some criteria.\n",
    "    - Applying a function to each group independently.\n",
    "    - Combining the results into a data structure.\n",
    "    \n",
    "---\n",
    "`.groupby()` is one of the most powerfull tool for feature engineering. Very often it is used to group object with the same categorical characteristics and compute some statistics (e.g. mean, max, etc.) of a their numerical characteric. \n",
    "\n",
    "Instead of computing average area of houses with high grade you could compute average areas of the\n",
    "houses for every grade in a single command:\n",
    "\n",
    "```\n",
    "data.groupby('grade')['sqm_tot_area'].mean()\n",
    "```\n",
    "\n",
    "You could also make multi-column groups:\n",
    "\n",
    "```\n",
    "data.groupby(['weekday','grade'])['price'].min()\n",
    "```\n",
    "next, you could compute multiple aggregation functions:\n",
    "```\n",
    "data.groupby(['weekday','grade'])['price'].agg([min, max])\n",
    "```\n",
    "\n",
    "instead of using built-in functions you could compute custom functions using apply:\n",
    "```\n",
    "import numpy as np\n",
    "data.groupby(['condition','grade'])['bathrooms'].apply(lambda x: np.quantile(x, .5))\n",
    "```\n",
    "\n",
    "and the coolest thing now is that you can map the results of groupby back on your DataFrame!\n",
    "```\n",
    "gp = data.groupby(['condition'])['bathrooms'].median()\n",
    "data['gp_feature'] = data['condition'].map(gp)\n",
    "```\n",
    "Now, if some house has `condition == 2`, its `gp_feature` will be equal to the median number of \n",
    "bathrooms amongst all houses with `condition == 2`.\n",
    "\n",
    "Read more examples in the documentation https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some groupby features\n",
    "\n",
    "# Q19.1 `price_by_class` groupby `high_class` and compute median `price`.\n",
    "# Q19.2 `price_by_year` groupby `year` and compute median price.\n",
    "# Q19.3 `price_by_weekday` groupby `weekday` and compute median price.\n",
    "# Q19.4 `area_by_price` groupby `price_cat` and compute average `sqft_living`.\n",
    "# Q19.5 `floors_by_age` groupby `floors` and compute average age of a house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some other groupby features\n",
    "# for this task check out this answer:\n",
    "# https://stackoverflow.com/questions/47913343/how-to-groupby-and-map-by-two-columns-pandas-dataframe\n",
    "\n",
    "# Q20.1 `n_houses_zipcode` groupby `zipcode` and count number of occurences of every unique zipcode\n",
    "# Q20.2 `n_houses_yr_built` groupby `yr_built` and count number of houses built in each year\n",
    "# Q20.3 `price_by_yr_month_`(median, std) groupby `year`, `month` and compute median and std `price`.\n",
    "# Q20.4 `price_by_grade_age_`(median, std) groupby `grade`, `house_age` and compute median and std `price`.\n",
    "# Q20.5 `living_by_cond_`(median, std) groupby `waterfront`, `view`, `condition` and compute median and std `sqft_living`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Building a regression model\n",
    "\n",
    "> You do not need to normalize data for tree models, and for linear/knn models this step is essential.\n",
    "\n",
    "> Remember, that not all of the features in the table are numeric, some of them might be viewed as categorical.\n",
    "\n",
    "> You may create or drop **any** features you want, except for the features which use `price` (e.g. average price of a house with 5 bedrooms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q21 Drop all generated features which used price column, e.g. price_by_year, price_cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q22 Split your data into train and test parts.\n",
    "# How many records (rows) do you have in train and test tables? (list of int)?\n",
    "# Use sklearn.model_selection.train_test_split with test_size=0.33 and random_state=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictive regression model of a house price.\n",
    "\n",
    "# Q23.1 Use linear regression with l2 regularization (Ridge regression)\n",
    "# Q23.2 Use decision tree regression\n",
    "# Q23.3 Use k nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use grid search to select optimal hyperparamters of your models. \n",
    "\n",
    "# Q24.1 Alpha for a ridge regression\n",
    "# Q24.2 Depth for the tree\n",
    "# Q24.3 Number of neighbours for the knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and test mean squared error for your best models (list of float).\n",
    "\n",
    "# Q25.1 Train, test MSE using linear regression with l2 regularization\n",
    "# Q25.2 Train, test MSE using decision tree regression\n",
    "# Q25.3 Train, test MSE using k nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and test R^2 for your best models (list of float).\n",
    "\n",
    "# Q26.1 Train, test R^2 using linear regression with l2 regularization\n",
    "# Q26.2 Train, test R^2 using decision tree regression\n",
    "# Q26.3 Train, test R^2 using k nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q27 Which features have largest (by absolute value) weight in your linear model (top 5 features)? (list of str)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure your .ipynb is linearly executable \n",
    "# Kernel -> Restart & Run All -> No ERROR cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q28 Save your .ipynb file: Name_Surname_HA1.ipynb, you will be asked to upload it into the google form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
